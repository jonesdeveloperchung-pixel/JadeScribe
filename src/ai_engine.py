import ollama
import json
import logging
import time
import os
import re
from typing import Dict, Any, Optional, List
from db_manager import log_telemetry
from utils import check_ollama_status
from vision_utils import ImageProcessor

# Configure Logging
logger = logging.getLogger(__name__)

# Constants
VISION_MODEL = os.getenv("VISION_MODEL", "llama3.2-vision:latest")
TEXT_MODEL = os.getenv("TEXT_MODEL", "gemma3n:e4b")
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434")

# Initialize Client explicitly to avoid localhost resolution issues
client = ollama.Client(host=OLLAMA_HOST)

# Initialize Image Processor
processor = ImageProcessor()

# Load Symbolism Glossary
GLOSSARY_PATH = os.path.join("data", "symbolism_glossary.json")
SYMBOLISM_GLOSSARY = {}
try:
    with open(GLOSSARY_PATH, 'r', encoding='utf-8') as f:
        SYMBOLISM_GLOSSARY = json.load(f)
    logger.info("Symbolism glossary loaded successfully.")
except FileNotFoundError:
    logger.error(f"Symbolism glossary not found at {GLOSSARY_PATH}. Descriptions may be generic.")
except json.JSONDecodeError:
    logger.error(f"Error decoding symbolism glossary at {GLOSSARY_PATH}. Descriptions may be generic.")


def _get_symbolism_context(motif: str, color: str) -> str:
    """
    Retrieves symbolism context from the loaded glossary based on detected features.
    """
    context_parts = []

    # Motif symbolism
    if motif and motif.lower() in SYMBOLISM_GLOSSARY.get("motifs", {}):
        motif_entry = SYMBOLISM_GLOSSARY["motifs"][motif.lower()]
        context_parts.append(f"åœ–æ¡ˆã€Œ{motif_entry['name'].split(' ')[0]}ã€è±¡å¾µè‘—ï¼š{motif_entry['meaning']}")
    
    # Color characteristics
    if color and color.lower() in SYMBOLISM_GLOSSARY.get("colors", {}):
        color_entry = SYMBOLISM_GLOSSARY["colors"][color.lower()]
        context_parts.append(f"æ­¤ç¿¡ç¿ çš„é¡è‰²ç‚ºã€Œ{color_entry.split(' ')[0]}ã€ï¼Œå…¶ç‰¹è‰²æ˜¯ï¼š{color_entry.split(' - ')[1]}")

    if context_parts:
        return "\n".join(context_parts)
    return ""

def clean_json_output(text: str) -> str:
    """
    Extracts the JSON-like substring from the text, removing Markdown code blocks.
    """
    # 1. Remove markdown code blocks ```json ... ``` or ``` ... ```
    text = re.sub(r'```json\s*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'```\s*', '', text)
    
    # 2. Find first [ or { and last ] or } to handle extra text around JSON
    # Try finding an Array
    list_match = re.search(r'\[.*\]', text, re.DOTALL)
    if list_match:
        return list_match.group(0)
    
    # Try finding an Object
    obj_match = re.search(r'\{.*\}', text, re.DOTALL)
    if obj_match:
        return obj_match.group(0)
        
    return text.strip()

def safe_chat_call(model, messages, options=None, format=None, retries=2):
    """
    Wraps client.chat with retry logic for network stability.
    """
    attempt = 0
    last_error = None
    
    while attempt <= retries:
        try:
            return client.chat(
                model=model,
                messages=messages,
                options=options,
                format=format
            )
        except Exception as e:
            last_error = e
            logger.warning(f"Ollama Call Failed (Attempt {attempt+1}/{retries+1}): {e}")
            attempt += 1
            time.sleep(1) # Wait 1s before retry
            
    raise last_error

def analyze_single_crop(image_path: str, ocr_code: str = "Unknown") -> Dict[str, Any]:
    """
    Analyzes a single cropped image with "Gemologist" Chain-of-Thought prompting.
    """
    prompt = f"""
    You are a professional Gemologist analyzing a high-resolution close-up of a Jade Pendant.
    
    Detected Item Code from Label: "{ocr_code}" (If "Unknown", try to read it from the image).

    Perform a "Zoom-In" Analysis:
    1. Transparency: Is it Opaque, Translucent (Waxy/Sticky), or Transparent (Icy/Glassy)?
    2. Texture: Describe the grain. Fine, coarse, or oily?
    3. Color: Describe the primary color and any floating flowers (piao hua).
    4. Motif: Identify the carved figure (e.g., Buddha, Leaf, Dragon).
    
    Return a JSON Object:
    {{
        "item_code": "{ocr_code if ocr_code != "Unknown" else "READ_FROM_IMAGE"}",
        "visual_features": {{
            "color": "...",
            "motif": "...",
            "characteristics": "Combine transparency and texture here..."
        }}
    }}
    """
    
    try:
        response = safe_chat_call(
            model=VISION_MODEL,
            messages=[{
                'role': 'user',
                'content': prompt,
                'images': [image_path]
            }],
            format='json',
            options={'temperature': 0.1}
        )
        
        content = response['message']['content']
        cleaned = clean_json_output(content)
        result = json.loads(cleaned)
        
        # Merge EasyOCR code if Vision model failed to read it or returned placeholder
        if ocr_code != "Unknown":
            result["item_code"] = ocr_code
            
        return result
    except Exception as e:
        logger.error(f"Crop analysis failed: {e}")
        return {
            "item_code": ocr_code,
            "visual_features": {
                "color": "Analysis Failed", 
                "motif": "Unknown", 
                "characteristics": "Error"
            }
        }

def analyze_image_content(image_path: str, enable_ocr: bool = True) -> List[Dict[str, Any]]:
    """
    Analyzes an image using a Hybrid Pipeline:
    1. Computer Vision Segmentation (Crops) + EasyOCR (Optional)
    2. AI Vision Analysis on Crops
    """
    start_time = time.time()
    
    # 1. Check Service
    status = check_ollama_status(base_url=OLLAMA_HOST)
    if not status["running"]:
        return [{"error": f"Ollama service is not running or accessible at {OLLAMA_HOST}."}]

    logger.info(f"Analyzing image: {image_path} (OCR Enabled: {enable_ocr})")
    
    # 2. Attempt Segmentation & Crop
    try:
        detected_crops = processor.segment_and_crop(image_path, enable_ocr=enable_ocr)
    except Exception as e:
        logger.error(f"Segmentation failed: {e}")
        detected_crops = []

    results = []

    # 3. Process Crops (Zoom-In Analysis)
    if detected_crops:
        logger.info(f"Segmentation found {len(detected_crops)} items. Running Zoom-In Analysis.")
        for item in detected_crops:
            crop_path = item["crop_path"]
            ocr_code = item["ocr_code"]
            
            # Analyze
            crop_result = analyze_single_crop(crop_path, ocr_code)
            
            # Add file path to result so UI can display the crop
            crop_result["crop_path"] = crop_path 
            results.append(crop_result)
            
    else:
        # 4. Fallback: Full Image Analysis (Old Method)
        logger.warning("No items segmented. Falling back to full image analysis.")
        prompt = """
        Analyze this image of jade pendants. Return a JSON ARRAY of items found.
        Extract Item Code and Visual Features (Color, Motif, Texture).
        """
        try:
            response = safe_chat_call(
                model=VISION_MODEL,
                messages=[{'role': 'user', 'content': prompt, 'images': [image_path]}],
                format='json',
                options={'temperature': 0.1}
            )
            content = response['message']['content']
            results = json.loads(clean_json_output(content))
            if isinstance(results, dict): results = [results]
        except Exception as e:
             return [{"error": str(e)}]

    duration = (time.time() - start_time) * 1000
    log_telemetry(
        module="ai_engine",
        action="analyze_image_hybrid",
        execution_data={"duration_ms": duration, "exit_code": 0, "items_found": len(results)},
        args=[image_path]
    )
    
    return results

def generate_marketing_copy(features: Dict[str, Any]) -> Dict[str, str]:
    """
    Generates three styles of Traditional Chinese descriptions:
    1. Hero (Poetic/Classical)
    2. Modern (E-commerce/Benefit-focused)
    3. Social (Short/Hashtags)
    """
    start_time = time.time()
    
    motif = features.get('visual_features', {}).get('motif', 'Unknown')
    color = features.get('visual_features', {}).get('color', 'Unknown')
    characteristics = features.get('visual_features', {}).get('characteristics', 'Unknown')
    
    # Get symbolism context
    symbolism_context = _get_symbolism_context(motif, color)
    symbolism_section = f"æ–‡åŒ–å¯“æ„åƒè€ƒ: {symbolism_context}" if symbolism_context else ""
    
    # Construct the Prompt
    prompt = f"""
    æ‚¨æ˜¯ä¸€ä½å°ˆæ¥­çš„é«˜ç«¯ç¿¡ç¿ ç å¯¶æ–‡æ¡ˆæ’°å¯«å°ˆå®¶ï¼Œç²¾é€šå°ç£å¸‚å ´çš„èªè¨€ç¿’æ…£ã€‚
    ç‰©ä»¶è©³ç´°è³‡æ–™ï¼š
    - ä¸»é¡Œ: {motif}
    - é¡è‰²: {color}
    - ç‰¹æ€§: {characteristics}
    {symbolism_section}
    
    ä»»å‹™ï¼šè«‹ç”Ÿæˆä¸‰ç¨®ä¸åŒé¢¨æ ¼çš„æ–‡æ¡ˆï¼Œå¿…é ˆä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ï¼ˆå°ç£ï¼‰ã€ä¸”ã€Œç¢ºä¿å®Œå…¨ä¸ä½¿ç”¨ç°¡é«”å­—ã€ã€‚
    è«‹åš´æ ¼éµå®ˆ JSON æ ¼å¼å›å‚³ï¼ŒåŒ…å«ä»¥ä¸‹ä¸‰å€‹éµï¼š "hero", "modern", "social"ã€‚
    
    1. "hero" (ç¶“å…¸æ•˜äº‹)ï¼šå„ªé›…ã€æ·±é‚ƒã€é«˜ç«¯ç•«å†Šé¢¨æ ¼ï¼ˆç´„ 100-150 å­—ï¼‰ã€‚è‘—é‡æ–¼è—è¡“æ„Ÿã€æ­·å²å‚³æ‰¿èˆ‡æ–‡åŒ–å¯“æ„ã€‚ä½¿ç”¨å„ªç¾çš„ä¿®è¾­ï¼Œå¦‚ã€Œæº«æ½¤å¦‚ç‰ã€ã€ã€Œæ­·ä¹…å½Œæ–°ã€ã€‚
    2. "modern" (ç¾ä»£é›»å•†)ï¼šç›´è§€ã€å°ˆæ¥­ã€åŠŸèƒ½å°å‘ã€‚ä½¿ç”¨æ¸…å–®æˆ–çŸ­å¥æè¿°æè³ªã€å…‰æ¾¤åŠä½©æˆ´æ„Ÿã€‚é©åˆå®˜ç¶²å•†å“è©³æƒ…ã€‚
    3. "social" (ç¤¾ç¾¤è²¼æ–‡)ï¼šæ´»æ½‘ã€å…·å¸å¼•åŠ›çš„ç¤¾ç¾¤åª’é«”é¢¨æ ¼ï¼ˆå¦‚ Instagram æˆ– Threadsï¼‰ã€‚å­—æ•¸ç°¡æ½”ï¼ŒåŒ…å« 3-5 å€‹ç›¸é—œ Emoji å’Œ Hashtagsã€‚
    
    è¼¸å‡º JSON æ ¼å¼ç¯„ä¾‹ï¼š
    {{
        "hero": "ç‰è‰²å¦‚å›å­ä¹‹å¿ƒ...",
        "modern": "æè³ªï¼šå¤©ç„¶ç¿¡ç¿ ...",
        "social": "ğŸ¾ è¶…å¯æ„›çš„ç¿¡ç¿ å°èŒç‰©..."
    }}
    """
    
    try:
        # Call with Retry
        response = safe_chat_call(
            model=TEXT_MODEL,
            messages=[{'role': 'user', 'content': prompt}],
            format='json',
            options={'temperature': 0.7}
        )
        
        content = response['message']['content']
        
        try:
            cleaned_content = clean_json_output(content)
            descriptions = json.loads(cleaned_content)
            
            # Defensive check for keys
            for key in ["hero", "modern", "social"]:
                if key not in descriptions:
                    descriptions[key] = "ç”Ÿæˆä¸å®Œæ•´ (Generation Incomplete)"
                    
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse Copy JSON. Raw: {content}")
            descriptions = {
                "hero": content,
                "modern": "æ ¼å¼éŒ¯èª¤ (Format Error)",
                "social": "æ ¼å¼éŒ¯èª¤ (Format Error)"
            }

        duration = (time.time() - start_time) * 1000
        log_telemetry(
            module="ai_engine",
            action="generate_marketing_copy",
            execution_data={"duration_ms": duration, "exit_code": 0}
        )
        
        return descriptions

    except Exception as e:
        duration = (time.time() - start_time) * 1000
        logger.error(f"Copy Generation Failed: {e}")
        log_telemetry(
            module="ai_engine",
            action="generate_marketing_copy",
            execution_data={"duration_ms": duration, "exit_code": 1, "error": str(e)}
        )
        return {
            "hero": "ç”Ÿæˆå¤±æ•— (Generation Failed)",
            "modern": "",
            "social": ""
        }

